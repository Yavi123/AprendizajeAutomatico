{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c47028",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===================  SVM  ===================== \n",
      "\n",
      "Accuracy :  72.75862068965517 %\n",
      "Matriz de Confusión:\n",
      "[[418   0  25   0   0   7   0]\n",
      " [  1   0   0   0   0   0   0]\n",
      " [168   0 194   0   0   3   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  9   0   0   0   0   0   0]\n",
      " [ 24   0   0   0   0  21   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Matriz de Confusión en bools:\n",
      "[[418  32]\n",
      " [202 218]]\n",
      "\n",
      " ===================  DECISION TREE  ===================== \n",
      "\n",
      "Accuracy :  80.11494252873564 %\n",
      "Matriz de Confusión:\n",
      "[[387   0  58   0   0   5   0]\n",
      " [  1   0   0   0   0   0   0]\n",
      " [ 73   0 289   0   0   3   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  9   0   0   0   0   0   0]\n",
      " [ 13   0  11   0   0  21   0]\n",
      " [  0   0   0   0   0   0   0]]\n",
      "Matriz de Confusión en bools:\n",
      "[[387  63]\n",
      " [ 96 324]]\n",
      "\n",
      " ===================  MLP  ===================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ann import costL2, backprop, forwardprop, iterateThetas\n",
    "\n",
    "from Utils import ExportThetasToFile\n",
    "from Utils import CreateTxt\n",
    "\n",
    "#print(pd.__version__)\n",
    "\n",
    "# EJERCICIO 2 - visualiza los datos\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "data = pd.read_csv(\"data/kartAllData.csv\", header=None, names=[\"dist1\", \"dist2\", \"dist3\", \"dist4\", \"dist5\", \n",
    "                                                           \"x\", \"y\", \"z\", \"tiempo\", \"accion\"])\n",
    "\n",
    "# Eliminar las columnas de posición y tiempo ya que consideramos que no son tan relevantes como la distancia de los raycast\n",
    "droppingPosition = True\n",
    "\n",
    "if (droppingPosition):\n",
    "    cleanDataset = data.drop([\"x\", \"y\", \"z\", \"tiempo\"], axis=1)\n",
    "    numInputs = 5\n",
    "else:\n",
    "    cleanDataset = data.drop([\"y\", \"tiempo\"], axis=1)\n",
    "    numInputs = 7\n",
    "    \n",
    "# Realizar one-hot encoding para la columna \"accion\"\n",
    "one_hot_encoded = pd.get_dummies(data[\"accion\"], prefix=\"accion\")\n",
    "\n",
    "# Añadir los valores generados del one_hot_encoded al dataset\n",
    "cleanDataset = pd.concat([cleanDataset, one_hot_encoded], axis=1)\n",
    "cleanDataset = cleanDataset.drop([\"accion\"], axis=1)\n",
    "\n",
    "# Utilizaremos los valores de las distancias de los 5 raycast como input\n",
    "X = cleanDataset.iloc[:, :numInputs]\n",
    "# Mientras que utilizaremos los 7 estados de accion, pasados por one_hot_encoded\n",
    "Y = cleanDataset.iloc[:, numInputs:]\n",
    "\n",
    "#==Normalizacion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaling=StandardScaler()\n",
    "scaling.fit(X)\n",
    "X=scaling.transform(X)\n",
    "\n",
    "\n",
    "#========================================================================================================\n",
    "#                    DIVIDIR DATOS ENTRE ENTRENAMIENTO Y DE TEST\n",
    "#========================================================================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, train_size = 0.8, random_state = 1234)\n",
    "\n",
    "\n",
    "# Visualizar la distribución de clases\n",
    "class_distribution = data[\"accion\"].value_counts()\n",
    "\n",
    "# Graficar la distribución de clases\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_distribution.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribución de Clases')\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Frecuencia')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# Los valores de Y_pred y Y_test tienen que tener el siguiente formato:\n",
    "# Y_pred =  [0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0  ... 0 0 0 0 0 2 0] \n",
    "def PrintData(Y_pred, Y_test) :\n",
    "    # Calcula el accuracy\n",
    "    acc = accuracy_score(Y_test, Y_pred)\n",
    "    \n",
    "    print(\"Accuracy : \", acc * 100, \"%\")\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    Y_test_np = np.array(Y_test, dtype=int)\n",
    "    Y_pred_np = np.array(Y_pred, dtype=int)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(Y_test_np, Y_pred_np, labels=[0, 1, 2, 3, 4, 5, 6])\n",
    "    \n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(conf_matrix)\n",
    "    Y_test_np = np.array(Y_test, dtype=bool)\n",
    "    Y_pred_np = np.array(Y_pred, dtype=bool)\n",
    "    \n",
    "    conf_matrix_bool = confusion_matrix(Y_test_np.flatten(), Y_pred_np.flatten())\n",
    "    \n",
    "    print(\"Matriz de Confusión en bools:\")\n",
    "    print(conf_matrix_bool)\n",
    "    \n",
    "\n",
    "\n",
    "# EJERCICIO 4 - Prueba diferentes modelos de Machine Learning\n",
    "\n",
    "Y_test = Y_test.to_numpy()\n",
    "Y_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "#========================================================================================================\n",
    "#                                                SVM\n",
    "#========================================================================================================\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "\n",
    "SVC_Y_train = np.argmax(Y, axis=1)\n",
    "classifier = classifier.fit(X, SVC_Y_train)\n",
    "\n",
    "Y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n ===================  SVM  ===================== \\n\")\n",
    "\n",
    "PrintData(Y_pred, Y_test)\n",
    "\n",
    "\n",
    "#========================================================================================================\n",
    "#                                          ARBOL DE DECISION\n",
    "#========================================================================================================\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=4)\n",
    "\n",
    "# Entrenar modelo\n",
    "decision_tree = decision_tree.fit(X, Y)\n",
    "\n",
    "# DESCOMENTAR PARA PRINTEAR EL ARBOL GENERADO\n",
    "### # Los nombres de los 5 rayos/parametros\n",
    "### ray_features = [\"ray1\", \"ray2\", \"ray3\", \"ray4\", \"ray5\"]\n",
    "### r = export_text(decision_tree, feature_names=ray_features)\n",
    "### print(r)\n",
    "### decision_tree.score(X_test, Y_test)\n",
    "\n",
    "# Predice las clases en el conjunto de prueba\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "#print(\"Y_pred = \", Y_pred[:100])\n",
    "\n",
    "\n",
    "print(\"\\n ===================  DECISION TREE  ===================== \\n\")\n",
    "\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "PrintData(Y_pred, Y_test)\n",
    "\n",
    "#========================================================================================================\n",
    "#                                                MLP\n",
    "#========================================================================================================\n",
    "\n",
    "# Entrenar modelo con backpropagation\n",
    "\n",
    "neuronsInputLayer = X.shape[1]\n",
    "neuronsFirstHiddenLayer = 6\n",
    "neuronsSecondHiddenLayer = 9\n",
    "neuronsThirdHiddenLayer = 7\n",
    "neuronsOutputLayer = Y.shape[1]\n",
    "\n",
    "e = 0.12\n",
    "iterations = 5000\n",
    "myAlpha = 0.9\n",
    "myLambda = 1.9\n",
    "\n",
    "thetas = []\n",
    "# Valores aleatorios en theta1 y theta2\n",
    "theta1 = np.random.uniform(low=-e, high=e, size=( neuronsFirstHiddenLayer, neuronsInputLayer+1))\n",
    "theta2 = np.random.uniform(low=-e, high=e, size=( neuronsSecondHiddenLayer, neuronsFirstHiddenLayer+1))\n",
    "theta3 = np.random.uniform(low=-e, high=e, size=( neuronsThirdHiddenLayer, neuronsSecondHiddenLayer+1))\n",
    "theta4 = np.random.uniform(low=-e, high=e, size=(neuronsOutputLayer, neuronsThirdHiddenLayer+1))\n",
    "#theta3 = np.random.uniform(low=-e, high=e, size=(99, +1))\n",
    "#theta4 = np.random.uniform(low=-e, high=e, size=(99, +1))\n",
    "\n",
    "## Ajustar thetha1 y theta2 teniendo en cuenta los parametros dados\n",
    "#thetas = iterateThetas([theta1, theta2], X, Y, iterations, myLambda, myAlpha)\n",
    "\n",
    "\n",
    "#=======================================================================================================\n",
    "#                             COMPARAR LOS RESULTADOS DE MLP CON SKLEARN\n",
    "#=======================================================================================================\n",
    "\n",
    "\n",
    "print(\"\\n ===================  MLP  ===================== \\n\" )\n",
    "# Entrenar a SKLearn con los mismos valores\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "hidden_layer_sizes = (neuronsFirstHiddenLayer)\n",
    "sklearn_neural_network = MLPClassifier(\n",
    "    alpha=myLambda, \n",
    "    learning_rate_init=myAlpha, \n",
    "    activation='logistic',\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    max_iter = iterations\n",
    ")\n",
    "sklearn_neural_network.fit(X, Y)\n",
    "\n",
    "\n",
    "# Ajustar thetha1 y theta2 teniendo en cuenta los parametros dados\n",
    "thetas = iterateThetas([theta1, theta2, theta3, theta4], X, Y, iterations, myLambda, myAlpha)\n",
    "\n",
    "#ExportThetasToFile(thetas, \"../Assets/modelo1.txt\")\n",
    "CreateTxt(thetas, \"../Assets/modelo2.txt\")\n",
    "\n",
    "\n",
    "## Realizar la propagación hacia adelante\n",
    "\n",
    "# Predicciones con MLPClassifier\n",
    "layerValues_sklearn = sklearn_neural_network.predict(X_test)\n",
    "sklearnPredictions = np.argmax(layerValues_sklearn, axis=1)\n",
    "#print(\"SklearnPredictions:\", sklearnPredictions[:1000])\n",
    "\n",
    "layerValues, weighted_inputs = forwardprop(thetas, X_test)\n",
    "#print(\"layerValues[-1].shape: \", layerValues[-1].shape)\n",
    "#print(\"Y_test.shape: \", Y_test.shape)\n",
    "#print(\"Y_test: \", Y_test[:100])\n",
    "\n",
    "myPredictions = np.argmax(layerValues[-1], axis=1)\n",
    "\n",
    "print(\"Our MLP:\")\n",
    "PrintData(myPredictions, Y_test)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"SKL MLP:\")\n",
    "PrintData(sklearnPredictions, Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecaf31d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our KNN:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PrintData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     predictions[i] \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur KNN:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m PrintData(predictions, Y_test)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PrintData' is not defined"
     ]
    }
   ],
   "source": [
    "from knn import predict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"data/Kart06.csv\", header=None)\n",
    "\n",
    "# Realizar one-hot encoding para la columna \"accion\"\n",
    "one_hot_encoded = pd.get_dummies(data[9], prefix=\"accion\")\n",
    "\n",
    "# Añadir los valores generados del one_hot_encoded al dataset\n",
    "data = pd.concat([data, one_hot_encoded], axis=1)\n",
    "data = data.drop([9], axis=1)\n",
    "\n",
    "X = data.iloc[:, :9].to_numpy()\n",
    "Y = data.iloc[:, 9:].to_numpy()\n",
    "\n",
    "# mismo problema que en unity, detectaria distancia 0 y -1 como mas parecidos a 0 y 2\n",
    "np.place(X, X == -1, 100)\n",
    "\n",
    "\n",
    "#========DIVIDIR DATOS ENTRE ENTRENAMIENTO Y DE TEST==========================\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, train_size = 0.8, random_state = 1234)\n",
    "\n",
    "Y = np.argmax(Y, axis=1)\n",
    "Y_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "predictions = np.zeros(X_test.shape[0], dtype=int)\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    p = predict(X, Y, X_test[i])\n",
    "    predictions[i] = p\n",
    "\n",
    "print(\"Our KNN:\")\n",
    "PrintData(predictions, Y_test)\n",
    "print(\"\\n\")\n",
    "    \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnClssifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knnClssifier.fit(X, Y)\n",
    "\n",
    "skPredictions = knnClssifier.predict(X_test)\n",
    "\n",
    "print(\"SKL KNN:\")\n",
    "PrintData(skPredictions, Y_test)\n",
    "print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3966acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a40afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e075f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

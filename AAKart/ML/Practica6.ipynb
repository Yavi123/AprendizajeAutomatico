{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c47028",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ann import costL2, backprop, forwardprop, iterateThetas\n",
    "\n",
    "from Utils import ExportAllformatsMLPSKlearn\n",
    "\n",
    "# EJERCICIO 2 - visualiza los datos\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "data = pd.read_csv(\"data/TrainData.csv\", header=None, names=[\"dist1\", \"dist2\", \"dist3\", \"dist4\", \"dist5\", \n",
    "                                                           \"x\", \"y\", \"z\", \"tiempo\", \"accion\"])\n",
    "\n",
    "# Visualizar la distribución de clases\n",
    "class_distribution = data[\"accion\"].value_counts()\n",
    "\n",
    "# Graficar la distribución de clases\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_distribution.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribución de Clases')\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Frecuencia')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# EJERCICIO 3 - Limpia el dataset\n",
    "\n",
    "# Eliminar las columnas de posición y tiempo ya que consideramos que no son tan relevantes como la distancia de los raycast\n",
    "cleanDataset = data.drop([\"y\", \"tiempo\"], axis=1)\n",
    "numInputs = 7\n",
    "\n",
    "# Realizar one-hot encoding para la columna \"accion\"\n",
    "one_hot_encoded = pd.get_dummies(data[\"accion\"], prefix=\"accion\")\n",
    "\n",
    "# Añadir los valores generados del one_hot_encoded al dataset\n",
    "cleanDataset = pd.concat([cleanDataset, one_hot_encoded], axis=1)\n",
    "cleanDataset = cleanDataset.drop([\"accion\"], axis=1)\n",
    "# EJERCICIO 4 - Prueba diferentes modelos de Machine Learning\n",
    "\n",
    "\n",
    "# Entrenar modelo con backpropagation\n",
    "\n",
    "# Utilizaremos los valores de las distancias de los 5 raycast como input\n",
    "X = cleanDataset.iloc[:, :numInputs]\n",
    "# Mientras que utilizaremos los 7 estados de accion, pasados por one_hot_encoded\n",
    "Y = cleanDataset.iloc[:, numInputs:]\n",
    "\n",
    "#==Normalizacion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaling=StandardScaler()\n",
    "scaling.fit(X)\n",
    "X=scaling.transform(X)\n",
    "\n",
    "\n",
    "neuronsInputLayer = X.shape[1]\n",
    "neuronsFirstHiddenLayer = 100\n",
    "neuronsOutputLayer = Y.shape[1]\n",
    "\n",
    "e = 0.12\n",
    "iterations = 100\n",
    "myAlpha = .5\n",
    "myLambda = 1\n",
    "\n",
    "# Valores aleatorios en theta1 y theta2\n",
    "theta1 = np.random.uniform(low=-e, high=e, size=( neuronsFirstHiddenLayer, neuronsInputLayer+1))\n",
    "theta2 = np.random.uniform(low=-e, high=e, size=(neuronsOutputLayer, neuronsFirstHiddenLayer+1))\n",
    "#theta3 = np.random.uniform(low=-e, high=e, size=(99, +1))\n",
    "#theta4 = np.random.uniform(low=-e, high=e, size=(99, +1))\n",
    "\n",
    "## Ajustar thetha1 y theta2 teniendo en cuenta los parametros dados\n",
    "#thetas = iterateThetas([theta1, theta2], X, Y, iterations, myLambda, myAlpha)\n",
    "\n",
    "\n",
    "#########################################################\n",
    "####### Compara los resultados con SKLearn ##############\n",
    "#########################################################\n",
    "\n",
    "# Entrenar a SKLearn con los mismos valores\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "hidden_layer_sizes = (neuronsFirstHiddenLayer)\n",
    "sklearn_neural_network = MLPClassifier(\n",
    "    alpha=myLambda, \n",
    "    learning_rate_init=myAlpha, \n",
    "    activation='logistic',\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    max_iter = iterations\n",
    ")\n",
    "sklearn_neural_network.fit(X, Y)\n",
    "\n",
    "\n",
    "# Ajustar thetha1 y theta2 teniendo en cuenta los parametros dados\n",
    "thetas = iterateThetas([theta1, theta2], X, Y, iterations, myLambda, myAlpha)\n",
    "\n",
    "#=======================Cargar / preparar datos de test=============================\n",
    "data_test = pd.read_csv(\"data/TestData.csv\", header=None, names=[\"dist1\", \"dist2\", \"dist3\", \"dist4\", \"dist5\", \n",
    "                                                           \"x\", \"y\", \"z\", \"tiempo\", \"accion\"])\n",
    "\n",
    "class_distribution_test = data_test[\"accion\"].value_counts()\n",
    "\n",
    "cleanDataset_test = data_test.drop([\"y\", \"tiempo\"], axis=1)\n",
    "\n",
    "one_hot_encoded_test = pd.get_dummies(data_test[\"accion\"], prefix=\"accion\")\n",
    "\n",
    "cleanDataset_test = pd.concat([cleanDataset_test, one_hot_encoded_test], axis=1)\n",
    "cleanDataset_test = cleanDataset_test.drop([\"accion\"], axis=1)\n",
    "\n",
    "X_test = cleanDataset_test.iloc[:, :numInputs]\n",
    "Y_test = cleanDataset_test.iloc[:, numInputs:]\n",
    "\n",
    "#==Normalizacion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaling=StandardScaler()\n",
    "scaling.fit(X_test)\n",
    "X_test=scaling.transform(X_test)\n",
    "#====================================================================================\n",
    "\n",
    "## Realizar la propagación hacia adelante\n",
    "\n",
    "# Predicciones con MLPClassifier\n",
    "#layerValues_sklearn = sklearn_neural_network.predict(X_test)\n",
    "#sklearnPredictions = np.argmax(layerValues_sklearn, axis=1)\n",
    "#print(\"SklearnPredictions:\", sklearnPredictions[:1000])\n",
    "\n",
    "picklefileName = \"modelo.pickle\"\n",
    "onixFileName = \"modelo.onnx\"\n",
    "jsonFileName = 'modelo.json'\n",
    "customFileName = 'modelo_custom.txt'\n",
    "\n",
    "# ExportAllformatsMLPSKlearn(thetas, X, picklefileName, onixFileName, jsonFileName, customFileName)\n",
    "\n",
    "layerValues, weighted_inputs = forwardprop(thetas, X_test)\n",
    "myPredictions = np.argmax(layerValues[-1], axis=1)\n",
    "\n",
    "YTest_Values = np.argmax(Y_test, axis=1)\n",
    "\n",
    "print(\"MyPredictions.shape: \", myPredictions.shape)\n",
    "print(\"YTest_Values.shape: \", YTest_Values.shape)\n",
    "print(\"MyPredictions:\", myPredictions[:549])\n",
    "print(\"YTest_Values:\", YTest_Values[:549])\n",
    "\n",
    "myAccuracy_booleans = myPredictions == YTest_Values\n",
    "myAccuracy = np.mean(myAccuracy_booleans) * 100\n",
    "print(\"Our accuracy : \", myAccuracy, \"%\")\n",
    "\n",
    "#layerValues, weighted_inputs = forwardprop(thetas, X)\n",
    "#myPredictions = np.argmax(layerValues[-1], axis=1)\n",
    "#\n",
    "#YTest_Predictions = np.argmax(Y_test, axis=1)\n",
    "#myAccuracy_booleans = myPredictions == sklearnPredictions\n",
    "#myAccuracy = np.mean(myAccuracy_booleans) * 100\n",
    "#print(\"SKL accuracy : \", myAccuracy, \"%\")\n",
    "\n",
    "## Tener las predicciones mas probables en \"predictions\"\n",
    "#predictions = np.argmax(layerValues[-1], axis=1)\n",
    "#totalCases = len(y_index_numeric)\n",
    "##Numero de veces que se ha acertado el valor\n",
    "#correctCases = np.sum(predictions == y_index_numeric)\n",
    "#accuracy = correctCases / totalCases\n",
    "\n",
    "##print(\"predictions:\", predictions[:-1000])\n",
    "#print(\"Accuracy : \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e93b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf60372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
